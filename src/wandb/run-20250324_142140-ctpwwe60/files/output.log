03/24/2025 14:21:45 [INFO] grammar_env.criterion.probability_criterion -- ProbabilityCriterion initialized with lower_bound=-200.00000
03/24/2025 14:21:46 [INFO] grammar_env.criterion.probability_criterion -- ProbabilityCriterion initialized with lower_bound=-200.00000
03/24/2025 14:21:46 [INFO] grammar_env.grammar_env -- Environment initialized with 1000 max productions, BinaryGrammarFactory(num_nt=4, num_pt=14, num_rhs=324, num_r=1296) binary grammar factory.
03/24/2025 14:21:46 [INFO] actor_critic -- ActorCritic initialized with 1,857,809 parameters, state_dim=1296, action_dim=1296, hidden_dim=512, n_layer=3
03/24/2025 14:21:46 [INFO] ppo -- PPO initialized with persistent_dir: log/4_1000_20250324_142117, device: cuda:0, config: PPOConfig(num_non_terminals=4, max_productions=1000, criterion='f1', num_sentences_per_score=256, num_sentences_per_batch=256, episodes_per_batch=8, n_updates_per_iteration=10, lr=0.0002, gamma=0.99, clip=0.2, actor_weight=1.0, critic_weight=0.5, entropy_weight=0.01, save_freq=20, seed=0, min_ep_rews_threshold=0.0, hidden_dim=512, n_layer=3)

03/24/2025 14:21:46 [INFO] ppo -- Learning... Running 1000 timesteps per episode, 8 episodes per batch for a total of 10000000 timesteps
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/edgarduc/miniconda3/envs/learning-pcfg/lib/python3.11/cProfile.py", line 191, in <module>
    main()
  File "/home/edgarduc/miniconda3/envs/learning-pcfg/lib/python3.11/cProfile.py", line 180, in main
    runctx(code, globs, None, options.outfile, options.sort)
  File "/home/edgarduc/miniconda3/envs/learning-pcfg/lib/python3.11/cProfile.py", line 20, in runctx
    return _pyprofile._Utils(Profile).runctx(statement, globals, locals,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/edgarduc/miniconda3/envs/learning-pcfg/lib/python3.11/profile.py", line 63, in runctx
    prof.runctx(statement, globals, locals)
  File "/home/edgarduc/miniconda3/envs/learning-pcfg/lib/python3.11/cProfile.py", line 101, in runctx
    exec(cmd, globals, locals)
  File "train.py", line 94, in <module>
    train(name, persistent_dir, args, ppo_config)
  File "train.py", line 36, in train
    ppo.learn(args.timesteps)
  File "/home/edgarduc/PCFG_Reinforcement_learning/src/ppo.py", line 222, in learn
    buffer: RolloutBuffer = self.rollout()
                            ^^^^^^^^^^^^^^
  File "/home/edgarduc/PCFG_Reinforcement_learning/src/ppo.py", line 338, in rollout
    action, log_prob, _ = self.actor_critic.act(obs)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/edgarduc/PCFG_Reinforcement_learning/src/actor_critic.py", line 132, in act
    torch.from_numpy(state).unsqueeze(dim=0)
    ^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Numpy is not available
